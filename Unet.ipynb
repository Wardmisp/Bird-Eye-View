{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PFE",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOT71lWzPs43/UZxg9YMU4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wardmisp/Bird-Eye-View/blob/main/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_UqO1Lm_TNU"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchsummary import summary"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P6TJyqtbhe5"
      },
      "source": [
        "Solve the padding = 'same' issue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "636CVhPq8GKZ"
      },
      "source": [
        "def padding_same(output_dim,input_dim, kernel, stride):\r\n",
        "  return (int((output_dim-((input_dim-kernel)/stride+1))*stride/2))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz3kXqxIHyGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f020b3-5b5c-4a5a-a2d3-d1b785c57241"
      },
      "source": [
        "class Net(torch.nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # 1\n",
        "        self.cnn_layers1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(4, 64, kernel_size=8, stride=2, padding=[padding_same(48,96,8,2),padding_same(72,144,8,2)]),\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "        \n",
        "        # 2\n",
        "        self.cnn_layers2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=6, stride=2, padding=[padding_same(24,48,6,2),padding_same(36,72,6,2)]),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "        \n",
        "        # 3\n",
        "        self.cnn_layers3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=[padding_same(12,24,4,2),padding_same(18,36,4,2)]),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            torch.nn.Upsample(scale_factor=2),\n",
        "            torch.nn.Conv2d(256, 128, kernel_size=6, stride=2, padding=[20,14]),\n",
        "            torch.nn.BatchNorm2d(128))\n",
        "        \n",
        "        # 4\n",
        "        self.cnn_layers4 = torch.nn.Sequential(\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            torch.nn.Upsample(scale_factor=2),\n",
        "            torch.nn.Conv2d(256, 64, kernel_size=6, stride=2, padding=[38,26]),\n",
        "            torch.nn.BatchNorm2d(64))\n",
        "        \n",
        "        #5\n",
        "        self.cnn_layers5 = torch.nn.Sequential(\n",
        "            torch.nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            torch.nn.Upsample(scale_factor=2),\n",
        "            torch.nn.Conv2d(128, 7, kernel_size=8, stride=2, padding=1),\n",
        "            torch.nn.Softmax())\n",
        "\n",
        "    # Defining the forward pass concat here\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers1(x)\n",
        "        y = self.cnn_layers2(x)\n",
        "        z = self.cnn_layers3(y)\n",
        "        y = torch.cat((y,z),-3)\n",
        "        y = self.cnn_layers4(y)\n",
        "        print(y.shape)\n",
        "        x = torch.cat((x,y),-3)\n",
        "        x = self.cnn_layers5(x)\n",
        "        return x\n",
        "\n",
        "# defining the model\n",
        "model = Net()    \n",
        "print(model)\n",
        "summary(model,(4, 144, 96))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (cnn_layers1): Sequential(\n",
            "    (0): Conv2d(4, 64, kernel_size=(8, 8), stride=(2, 2), padding=[3, 3])\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (cnn_layers2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2), padding=[2, 2])\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (cnn_layers3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=[1, 1])\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (4): Conv2d(256, 128, kernel_size=(6, 6), stride=(2, 2), padding=[20, 14])\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (cnn_layers4): Sequential(\n",
            "    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (2): Conv2d(256, 64, kernel_size=(6, 6), stride=(2, 2), padding=[38, 26])\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (cnn_layers5): Sequential(\n",
            "    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (2): Conv2d(128, 7, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))\n",
            "    (3): Softmax(dim=None)\n",
            "  )\n",
            ")\n",
            "torch.Size([2, 64, 72, 48])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 72, 48]          16,448\n",
            "         LeakyReLU-2           [-1, 64, 72, 48]               0\n",
            "            Conv2d-3          [-1, 128, 36, 24]         295,040\n",
            "       BatchNorm2d-4          [-1, 128, 36, 24]             256\n",
            "         LeakyReLU-5          [-1, 128, 36, 24]               0\n",
            "            Conv2d-6          [-1, 256, 18, 12]         524,544\n",
            "       BatchNorm2d-7          [-1, 256, 18, 12]             512\n",
            "         LeakyReLU-8          [-1, 256, 18, 12]               0\n",
            "          Upsample-9          [-1, 256, 36, 24]               0\n",
            "           Conv2d-10          [-1, 128, 36, 24]       1,179,776\n",
            "      BatchNorm2d-11          [-1, 128, 36, 24]             256\n",
            "        LeakyReLU-12          [-1, 256, 36, 24]               0\n",
            "         Upsample-13          [-1, 256, 72, 48]               0\n",
            "           Conv2d-14           [-1, 64, 72, 48]         589,888\n",
            "      BatchNorm2d-15           [-1, 64, 72, 48]             128\n",
            "        LeakyReLU-16          [-1, 128, 72, 48]               0\n",
            "         Upsample-17         [-1, 128, 144, 96]               0\n",
            "           Conv2d-18            [-1, 7, 70, 46]          57,351\n",
            "          Softmax-19            [-1, 7, 70, 46]               0\n",
            "================================================================\n",
            "Total params: 2,664,199\n",
            "Trainable params: 2,664,199\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.21\n",
            "Forward/backward pass size (MB): 39.58\n",
            "Params size (MB): 10.16\n",
            "Estimated Total Size (MB): 49.95\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}